{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pONO-GA1ond9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlHeLOuNFftn"
   },
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6bfzFrLH03Yk"
   },
   "outputs": [],
   "source": [
    "def loading_document(filename):\n",
    "\n",
    "\tfile = open(filename, 'r')\n",
    "\n",
    "\tcontent = file.read()\n",
    "\n",
    "\tfile.close()\n",
    "\treturn content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QS-2u17F1NTB"
   },
   "outputs": [],
   "source": [
    "in_filename = 'plato_text.txt'\n",
    "document = loading_document(in_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0RLV4MfzDDO",
    "outputId": "cb76243c-be0c-45c0-ea0e-3b9f8aa67030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of The Republic, by Plato\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, gi\n"
     ]
    }
   ],
   "source": [
    "print(document[:175])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_c3D5s_Fr6X"
   },
   "source": [
    "#### Data Cleaning and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZiRYOh2PzXtT"
   },
   "outputs": [],
   "source": [
    "import string\n",
    " \n",
    "\n",
    "def scouring_document(document):\n",
    "\t\n",
    "\tdocument = document.replace('--', ' ')\n",
    "\ttoken_doc = document.split()\n",
    "\tstructure = str.maketrans('', '', string.punctuation)\n",
    "\ttoken_doc = [w.translate(structure) for w in token_doc]\n",
    "\ttoken_doc = [word for word in token_doc if word.isalpha()]\n",
    "\ttoken_doc = [word.lower() for word in token_doc]\n",
    "\n",
    "\treturn token_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VREnZYQm0PI8",
    "outputId": "f3abc6f4-b812-4cb6-fc69-088964223641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 216791\n",
      "Number of Unique Tokens: 10454\n"
     ]
    }
   ],
   "source": [
    "token_doc = scouring_document(document)\n",
    "print('Number of Tokens: %d' % len(token_doc))\n",
    "print('Number of Unique Tokens: %d' % len(set(token_doc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJjAr6JjFyvs"
   },
   "source": [
    "#### Data Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWTaJBke1hNd",
    "outputId": "035946c2-4911-4c8a-e2e0-39881c3f9638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 216740\n"
     ]
    }
   ],
   "source": [
    "span = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(span, len(token_doc)):\n",
    "\t\n",
    "\ttemp_seq = token_doc[i-span:i]\n",
    "\t\n",
    "\tline = ' '.join(temp_seq)\n",
    "\t\n",
    "\tsequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g6pEoLJs1w6Y"
   },
   "outputs": [],
   "source": [
    "def saving_document(lines, filename):\n",
    "\tinfo = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w')\n",
    "\tfile.write(info)\n",
    "\tfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_33sDsXd2CjC"
   },
   "outputs": [],
   "source": [
    "out_filename = 'plato_text_output.txt'\n",
    "saving_document(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEOqXMhEF7h-"
   },
   "source": [
    "### Training the model for Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox32GvkNGB4G"
   },
   "source": [
    "#### Loading Input Sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VnBOmy2f2QrM"
   },
   "outputs": [],
   "source": [
    "def loading_document(filename):\n",
    "\t\n",
    "\tfile = open(filename, 'r')\n",
    "\t\n",
    "\tcontent = file.read()\n",
    "\t\n",
    "\tfile.close()\n",
    "\treturn content\n",
    " \n",
    "\n",
    "in_filename = 'plato_text_output.txt'\n",
    "document = loading_document(in_filename)\n",
    "lines = document.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNgk0LXJGH15"
   },
   "source": [
    "#### Integer Encoding for Sequences for Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UR4Ye-CX2_Uj"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TOO5I5Tn2m3E"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4el9WpRG3V1Q"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joUKuw89HtOa"
   },
   "source": [
    "#### Segregating into Input and Output Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Q-ACPcTq3e4e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ABgu0BIA3YXr"
   },
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X_data, y_data = sequences[:,:-1], sequences[:,-1]\n",
    "y_data = to_categorical(y_data, num_classes=vocab_size)\n",
    "chronology_len = X_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoDv41tOI0h_"
   },
   "source": [
    "#### Model Creation and Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ABKDI3v_5Ca5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "keras=tf.keras\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2umqmYoi5dQN"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "xxIUBVV34y05"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 50, input_length=chronology_len))\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LqGI-GK1NsT9"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"weights.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LSMUQELry3hr",
    "outputId": "b57a0015-167a-448b-b205-cab27a22ea5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 639/3387 [====>.........................] - ETA: 8:25 - loss: 6.5251 - accuracy: 0.0682\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "1279/3387 [==========>...................] - ETA: 6:09 - loss: 6.3819 - accuracy: 0.0727\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "1919/3387 [===============>..............] - ETA: 4:18 - loss: 6.2987 - accuracy: 0.0800\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "2559/3387 [=====================>........] - ETA: 2:25 - loss: 6.2298 - accuracy: 0.0866\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "3199/3387 [===========================>..] - ETA: 32s - loss: 6.1840 - accuracy: 0.0914\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 593s 173ms/step - loss: 6.1741 - accuracy: 0.0926\n",
      "Epoch 2/100\n",
      " 452/3387 [===>..........................] - ETA: 8:03 - loss: 5.8667 - accuracy: 0.1135\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "1092/3387 [========>.....................] - ETA: 6:20 - loss: 5.8648 - accuracy: 0.1138\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "1732/3387 [==============>...............] - ETA: 4:35 - loss: 5.8611 - accuracy: 0.1143\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "2372/3387 [====================>.........] - ETA: 2:48 - loss: 5.8451 - accuracy: 0.1155\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "3012/3387 [=========================>....] - ETA: 1:02 - loss: 5.8297 - accuracy: 0.1177\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 564s 167ms/step - loss: 5.8186 - accuracy: 0.1190\n",
      "Epoch 3/100\n",
      " 265/3387 [=>............................] - ETA: 8:33 - loss: 5.6501 - accuracy: 0.1321\n",
      "Epoch 3: saving model to weights.ckpt\n",
      " 905/3387 [=======>......................] - ETA: 7:43 - loss: 5.6327 - accuracy: 0.1332\n",
      "Epoch 3: saving model to weights.ckpt\n",
      "1545/3387 [============>.................] - ETA: 5:47 - loss: 5.6332 - accuracy: 0.1338\n",
      "Epoch 3: saving model to weights.ckpt\n",
      "2185/3387 [==================>...........] - ETA: 3:38 - loss: 5.6296 - accuracy: 0.1359\n",
      "Epoch 3: saving model to weights.ckpt\n",
      "2825/3387 [========================>.....] - ETA: 1:40 - loss: 5.6169 - accuracy: 0.1369\n",
      "Epoch 3: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 598s 177ms/step - loss: 5.6155 - accuracy: 0.1373\n",
      "Epoch 4/100\n",
      "  78/3387 [..............................] - ETA: 8:55 - loss: 5.4750 - accuracy: 0.1532\n",
      "Epoch 4: saving model to weights.ckpt\n",
      " 718/3387 [=====>........................] - ETA: 7:11 - loss: 5.4697 - accuracy: 0.1513\n",
      "Epoch 4: saving model to weights.ckpt\n",
      " 981/3387 [=======>......................] - ETA: 6:31 - loss: 5.4768 - accuracy: 0.1498"
     ]
    }
   ],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=10*batch_size)\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Train the model with this callback\n",
    "model.fit(X_data, y_data, batch_size=batch_size, epochs=100,\n",
    "          callbacks=[cp_callback],\n",
    "          verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "H5ObUuVCzMxg",
    "outputId": "0aa8428c-10bd-40d9-ed75-fba1a14c7e61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weights.ckpt'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DnE25LZzQwu",
    "outputId": "c026e9fa-5f2b-434f-93cc-83a8b55dd057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6774/6774 - 125s - loss: 4.7130 - accuracy: 0.2013 - 125s/epoch - 18ms/step\n",
      "Restored model, accuracy: 20.13%\n"
     ]
    }
   ],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Load the previously saved weights\n",
    "model.load_weights(latest)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(X_data, y_data, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Fxlv5BCd1dVu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 639/3387 [====>.........................] - ETA: 5:12 - loss: 4.8179 - accuracy: 0.1981\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "1279/3387 [==========>...................] - ETA: 3:55 - loss: 4.8342 - accuracy: 0.1964\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "1919/3387 [===============>..............] - ETA: 2:42 - loss: 4.8295 - accuracy: 0.1961\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "2559/3387 [=====================>........] - ETA: 1:30 - loss: 4.8363 - accuracy: 0.1951\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "3199/3387 [===========================>..] - ETA: 20s - loss: 4.8370 - accuracy: 0.1956\n",
      "Epoch 1: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 374s 109ms/step - loss: 4.8373 - accuracy: 0.1956\n",
      "Epoch 2/25\n",
      " 452/3387 [===>..........................] - ETA: 5:25 - loss: 4.7881 - accuracy: 0.1942\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "1092/3387 [========>.....................] - ETA: 4:12 - loss: 4.7984 - accuracy: 0.1976\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "1732/3387 [==============>...............] - ETA: 3:04 - loss: 4.8121 - accuracy: 0.1975\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "2372/3387 [====================>.........] - ETA: 1:52 - loss: 4.8100 - accuracy: 0.1976\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "3012/3387 [=========================>....] - ETA: 41s - loss: 4.8157 - accuracy: 0.1972\n",
      "Epoch 2: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 378s 112ms/step - loss: 4.8202 - accuracy: 0.1966\n",
      "Epoch 3/25\n",
      " 265/3387 [=>............................] - ETA: 5:28 - loss: 4.7741 - accuracy: 0.1986\n",
      "Epoch 3: saving model to weights.ckpt\n",
      " 905/3387 [=======>......................] - ETA: 4:19 - loss: 4.7716 - accuracy: 0.2004\n",
      "Epoch 3: saving model to weights.ckpt\n",
      "1545/3387 [============>.................] - ETA: 3:12 - loss: 4.7883 - accuracy: 0.1995\n",
      "Epoch 3: saving model to weights.ckpt\n",
      "2185/3387 [==================>...........] - ETA: 2:05 - loss: 4.7981 - accuracy: 0.1988\n",
      "Epoch 3: saving model to weights.ckpt\n",
      "2825/3387 [========================>.....] - ETA: 59s - loss: 4.7974 - accuracy: 0.1992\n",
      "Epoch 3: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 357s 105ms/step - loss: 4.8042 - accuracy: 0.1988\n",
      "Epoch 4/25\n",
      "  78/3387 [..............................] - ETA: 5:58 - loss: 4.7915 - accuracy: 0.2011\n",
      "Epoch 4: saving model to weights.ckpt\n",
      " 718/3387 [=====>........................] - ETA: 5:00 - loss: 4.7762 - accuracy: 0.1996\n",
      "Epoch 4: saving model to weights.ckpt\n",
      "1358/3387 [===========>..................] - ETA: 3:45 - loss: 4.7895 - accuracy: 0.1986\n",
      "Epoch 4: saving model to weights.ckpt\n",
      "1998/3387 [================>.............] - ETA: 2:37 - loss: 4.7877 - accuracy: 0.1987\n",
      "Epoch 4: saving model to weights.ckpt\n",
      "2638/3387 [======================>.......] - ETA: 1:24 - loss: 4.7863 - accuracy: 0.1993\n",
      "Epoch 4: saving model to weights.ckpt\n",
      "3278/3387 [============================>.] - ETA: 12s - loss: 4.7874 - accuracy: 0.1997\n",
      "Epoch 4: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 382s 113ms/step - loss: 4.7866 - accuracy: 0.1999\n",
      "Epoch 5/25\n",
      " 531/3387 [===>..........................] - ETA: 5:23 - loss: 4.7414 - accuracy: 0.2030\n",
      "Epoch 5: saving model to weights.ckpt\n",
      "1171/3387 [=========>....................] - ETA: 4:12 - loss: 4.7486 - accuracy: 0.2018\n",
      "Epoch 5: saving model to weights.ckpt\n",
      "1811/3387 [===============>..............] - ETA: 2:58 - loss: 4.7569 - accuracy: 0.2018\n",
      "Epoch 5: saving model to weights.ckpt\n",
      "2451/3387 [====================>.........] - ETA: 1:45 - loss: 4.7652 - accuracy: 0.2008\n",
      "Epoch 5: saving model to weights.ckpt\n",
      "3091/3387 [==========================>...] - ETA: 33s - loss: 4.7690 - accuracy: 0.2001\n",
      "Epoch 5: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 382s 113ms/step - loss: 4.7724 - accuracy: 0.2000\n",
      "Epoch 6/25\n",
      " 344/3387 [==>...........................] - ETA: 5:23 - loss: 4.7414 - accuracy: 0.1997\n",
      "Epoch 6: saving model to weights.ckpt\n",
      " 984/3387 [=======>......................] - ETA: 4:24 - loss: 4.7365 - accuracy: 0.2017\n",
      "Epoch 6: saving model to weights.ckpt\n",
      "1624/3387 [=============>................] - ETA: 3:11 - loss: 4.7451 - accuracy: 0.2019\n",
      "Epoch 6: saving model to weights.ckpt\n",
      "2264/3387 [===================>..........] - ETA: 2:02 - loss: 4.7487 - accuracy: 0.2018\n",
      "Epoch 6: saving model to weights.ckpt\n",
      "2904/3387 [========================>.....] - ETA: 52s - loss: 4.7524 - accuracy: 0.2017\n",
      "Epoch 6: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 366s 108ms/step - loss: 4.7577 - accuracy: 0.2013\n",
      "Epoch 7/25\n",
      " 157/3387 [>.............................] - ETA: 5:43 - loss: 4.7346 - accuracy: 0.2062\n",
      "Epoch 7: saving model to weights.ckpt\n",
      " 797/3387 [======>.......................] - ETA: 4:35 - loss: 4.7193 - accuracy: 0.2051\n",
      "Epoch 7: saving model to weights.ckpt\n",
      "1437/3387 [===========>..................] - ETA: 3:27 - loss: 4.7314 - accuracy: 0.2021\n",
      "Epoch 7: saving model to weights.ckpt\n",
      "2077/3387 [=================>............] - ETA: 2:18 - loss: 4.7380 - accuracy: 0.2027\n",
      "Epoch 7: saving model to weights.ckpt\n",
      "2717/3387 [=======================>......] - ETA: 1:10 - loss: 4.7409 - accuracy: 0.2025\n",
      "Epoch 7: saving model to weights.ckpt\n",
      "3357/3387 [============================>.] - ETA: 3s - loss: 4.7465 - accuracy: 0.2021\n",
      "Epoch 7: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 359s 106ms/step - loss: 4.7459 - accuracy: 0.2022\n",
      "Epoch 8/25\n",
      " 610/3387 [====>.........................] - ETA: 5:27 - loss: 4.7115 - accuracy: 0.2027\n",
      "Epoch 8: saving model to weights.ckpt\n",
      "1250/3387 [==========>...................] - ETA: 5:08 - loss: 4.7148 - accuracy: 0.2041\n",
      "Epoch 8: saving model to weights.ckpt\n",
      "1890/3387 [===============>..............] - ETA: 3:24 - loss: 4.7203 - accuracy: 0.2040\n",
      "Epoch 8: saving model to weights.ckpt\n",
      "2530/3387 [=====================>........] - ETA: 1:54 - loss: 4.7258 - accuracy: 0.2036\n",
      "Epoch 8: saving model to weights.ckpt\n",
      "3170/3387 [===========================>..] - ETA: 28s - loss: 4.7301 - accuracy: 0.2030\n",
      "Epoch 8: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 439s 130ms/step - loss: 4.7345 - accuracy: 0.2028\n",
      "Epoch 9/25\n",
      " 423/3387 [==>...........................] - ETA: 5:25 - loss: 4.6667 - accuracy: 0.2077\n",
      "Epoch 9: saving model to weights.ckpt\n",
      "1063/3387 [========>.....................] - ETA: 4:14 - loss: 4.6903 - accuracy: 0.2067\n",
      "Epoch 9: saving model to weights.ckpt\n",
      "1703/3387 [==============>...............] - ETA: 3:07 - loss: 4.6982 - accuracy: 0.2061\n",
      "Epoch 9: saving model to weights.ckpt\n",
      "2343/3387 [===================>..........] - ETA: 1:57 - loss: 4.7026 - accuracy: 0.2057\n",
      "Epoch 9: saving model to weights.ckpt\n",
      "2983/3387 [=========================>....] - ETA: 45s - loss: 4.7151 - accuracy: 0.2047\n",
      "Epoch 9: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 380s 112ms/step - loss: 4.7200 - accuracy: 0.2042\n",
      "Epoch 10/25\n",
      " 236/3387 [=>............................] - ETA: 5:42 - loss: 4.6572 - accuracy: 0.2101\n",
      "Epoch 10: saving model to weights.ckpt\n",
      " 876/3387 [======>.......................] - ETA: 4:42 - loss: 4.6771 - accuracy: 0.2061\n",
      "Epoch 10: saving model to weights.ckpt\n",
      "1516/3387 [============>.................] - ETA: 3:33 - loss: 4.6912 - accuracy: 0.2055\n",
      "Epoch 10: saving model to weights.ckpt\n",
      "2156/3387 [==================>...........] - ETA: 2:18 - loss: 4.6986 - accuracy: 0.2048\n",
      "Epoch 10: saving model to weights.ckpt\n",
      "2796/3387 [=======================>......] - ETA: 1:06 - loss: 4.7020 - accuracy: 0.2053\n",
      "Epoch 10: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 381s 112ms/step - loss: 4.7117 - accuracy: 0.2046\n",
      "Epoch 11/25\n",
      "  49/3387 [..............................] - ETA: 6:01 - loss: 4.7146 - accuracy: 0.2018\n",
      "Epoch 11: saving model to weights.ckpt\n",
      " 689/3387 [=====>........................] - ETA: 4:57 - loss: 4.6752 - accuracy: 0.2063\n",
      "Epoch 11: saving model to weights.ckpt\n",
      "1329/3387 [==========>...................] - ETA: 3:47 - loss: 4.6794 - accuracy: 0.2068\n",
      "Epoch 11: saving model to weights.ckpt\n",
      "1969/3387 [================>.............] - ETA: 2:37 - loss: 4.6923 - accuracy: 0.2049\n",
      "Epoch 11: saving model to weights.ckpt\n",
      "2609/3387 [======================>.......] - ETA: 1:26 - loss: 4.6953 - accuracy: 0.2054\n",
      "Epoch 11: saving model to weights.ckpt\n",
      "3249/3387 [===========================>..] - ETA: 15s - loss: 4.6986 - accuracy: 0.2057\n",
      "Epoch 11: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 389s 115ms/step - loss: 4.6985 - accuracy: 0.2057\n",
      "Epoch 12/25\n",
      " 502/3387 [===>..........................] - ETA: 5:28 - loss: 4.6702 - accuracy: 0.2093\n",
      "Epoch 12: saving model to weights.ckpt\n",
      "1142/3387 [=========>....................] - ETA: 4:18 - loss: 4.6741 - accuracy: 0.2074\n",
      "Epoch 12: saving model to weights.ckpt\n",
      "1782/3387 [==============>...............] - ETA: 3:03 - loss: 4.6760 - accuracy: 0.2075\n",
      "Epoch 12: saving model to weights.ckpt\n",
      "2422/3387 [====================>.........] - ETA: 1:50 - loss: 4.6757 - accuracy: 0.2074\n",
      "Epoch 12: saving model to weights.ckpt\n",
      "3062/3387 [==========================>...] - ETA: 36s - loss: 4.6838 - accuracy: 0.2070\n",
      "Epoch 12: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 384s 113ms/step - loss: 4.6851 - accuracy: 0.2072\n",
      "Epoch 13/25\n",
      " 315/3387 [=>............................] - ETA: 5:51 - loss: 4.6593 - accuracy: 0.2076\n",
      "Epoch 13: saving model to weights.ckpt\n",
      " 955/3387 [=======>......................] - ETA: 4:34 - loss: 4.6591 - accuracy: 0.2073\n",
      "Epoch 13: saving model to weights.ckpt\n",
      "1595/3387 [=============>................] - ETA: 3:21 - loss: 4.6669 - accuracy: 0.2066\n",
      "Epoch 13: saving model to weights.ckpt\n",
      "2235/3387 [==================>...........] - ETA: 2:08 - loss: 4.6687 - accuracy: 0.2076\n",
      "Epoch 13: saving model to weights.ckpt\n",
      "2875/3387 [========================>.....] - ETA: 57s - loss: 4.6736 - accuracy: 0.2074\n",
      "Epoch 13: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 389s 115ms/step - loss: 4.6776 - accuracy: 0.2068\n",
      "Epoch 14/25\n",
      " 128/3387 [>.............................] - ETA: 6:09 - loss: 4.6511 - accuracy: 0.2091\n",
      "Epoch 14: saving model to weights.ckpt\n",
      " 768/3387 [=====>........................] - ETA: 4:52 - loss: 4.6599 - accuracy: 0.2071\n",
      "Epoch 14: saving model to weights.ckpt\n",
      "1408/3387 [===========>..................] - ETA: 3:40 - loss: 4.6570 - accuracy: 0.2080\n",
      "Epoch 14: saving model to weights.ckpt\n",
      "2048/3387 [=================>............] - ETA: 2:27 - loss: 4.6553 - accuracy: 0.2086\n",
      "Epoch 14: saving model to weights.ckpt\n",
      "2688/3387 [======================>.......] - ETA: 1:16 - loss: 4.6581 - accuracy: 0.2090\n",
      "Epoch 14: saving model to weights.ckpt\n",
      "3328/3387 [============================>.] - ETA: 6s - loss: 4.6659 - accuracy: 0.2084\n",
      "Epoch 14: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 372s 110ms/step - loss: 4.6666 - accuracy: 0.2083\n",
      "Epoch 15/25\n",
      " 581/3387 [====>.........................] - ETA: 5:06 - loss: 4.6325 - accuracy: 0.2095\n",
      "Epoch 15: saving model to weights.ckpt\n",
      "1221/3387 [=========>....................] - ETA: 3:55 - loss: 4.6343 - accuracy: 0.2103\n",
      "Epoch 15: saving model to weights.ckpt\n",
      "1861/3387 [===============>..............] - ETA: 2:47 - loss: 4.6396 - accuracy: 0.2097\n",
      "Epoch 15: saving model to weights.ckpt\n",
      "2501/3387 [=====================>........] - ETA: 1:38 - loss: 4.6437 - accuracy: 0.2094\n",
      "Epoch 15: saving model to weights.ckpt\n",
      "3141/3387 [==========================>...] - ETA: 27s - loss: 4.6533 - accuracy: 0.2089\n",
      "Epoch 15: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 381s 112ms/step - loss: 4.6547 - accuracy: 0.2089\n",
      "Epoch 16/25\n",
      " 394/3387 [==>...........................] - ETA: 5:58 - loss: 4.6321 - accuracy: 0.2098\n",
      "Epoch 16: saving model to weights.ckpt\n",
      "1034/3387 [========>.....................] - ETA: 4:47 - loss: 4.6376 - accuracy: 0.2094\n",
      "Epoch 16: saving model to weights.ckpt\n",
      "1674/3387 [=============>................] - ETA: 3:25 - loss: 4.6441 - accuracy: 0.2102\n",
      "Epoch 16: saving model to weights.ckpt\n",
      "2314/3387 [===================>..........] - ETA: 2:06 - loss: 4.6467 - accuracy: 0.2103\n",
      "Epoch 16: saving model to weights.ckpt\n",
      "2954/3387 [=========================>....] - ETA: 50s - loss: 4.6458 - accuracy: 0.2102\n",
      "Epoch 16: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 397s 117ms/step - loss: 4.6495 - accuracy: 0.2099\n",
      "Epoch 17/25\n",
      " 207/3387 [>.............................] - ETA: 5:46 - loss: 4.6056 - accuracy: 0.2099\n",
      "Epoch 17: saving model to weights.ckpt\n",
      " 847/3387 [======>.......................] - ETA: 4:54 - loss: 4.6113 - accuracy: 0.2143\n",
      "Epoch 17: saving model to weights.ckpt\n",
      "1487/3387 [============>.................] - ETA: 3:38 - loss: 4.6212 - accuracy: 0.2127\n",
      "Epoch 17: saving model to weights.ckpt\n",
      "2127/3387 [=================>............] - ETA: 2:24 - loss: 4.6280 - accuracy: 0.2123\n",
      "Epoch 17: saving model to weights.ckpt\n",
      "2767/3387 [=======================>......] - ETA: 1:11 - loss: 4.6347 - accuracy: 0.2114\n",
      "Epoch 17: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 389s 115ms/step - loss: 4.6403 - accuracy: 0.2109\n",
      "Epoch 18/25\n",
      "  20/3387 [..............................] - ETA: 6:38 - loss: 4.5029 - accuracy: 0.2352\n",
      "Epoch 18: saving model to weights.ckpt\n",
      " 660/3387 [====>.........................] - ETA: 5:20 - loss: 4.6162 - accuracy: 0.2119\n",
      "Epoch 18: saving model to weights.ckpt\n",
      "1300/3387 [==========>...................] - ETA: 4:12 - loss: 4.6062 - accuracy: 0.2139\n",
      "Epoch 18: saving model to weights.ckpt\n",
      "1940/3387 [================>.............] - ETA: 2:50 - loss: 4.6185 - accuracy: 0.2129\n",
      "Epoch 18: saving model to weights.ckpt\n",
      "2580/3387 [=====================>........] - ETA: 1:34 - loss: 4.6178 - accuracy: 0.2129\n",
      "Epoch 18: saving model to weights.ckpt\n",
      "3220/3387 [===========================>..] - ETA: 19s - loss: 4.6279 - accuracy: 0.2119\n",
      "Epoch 18: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 396s 117ms/step - loss: 4.6283 - accuracy: 0.2120\n",
      "Epoch 19/25\n",
      " 473/3387 [===>..........................] - ETA: 5:39 - loss: 4.6004 - accuracy: 0.2116\n",
      "Epoch 19: saving model to weights.ckpt\n",
      "1113/3387 [========>.....................] - ETA: 4:18 - loss: 4.5984 - accuracy: 0.2122\n",
      "Epoch 19: saving model to weights.ckpt\n",
      "1753/3387 [==============>...............] - ETA: 3:03 - loss: 4.6024 - accuracy: 0.2124\n",
      "Epoch 19: saving model to weights.ckpt\n",
      "2393/3387 [====================>.........] - ETA: 1:51 - loss: 4.6073 - accuracy: 0.2122\n",
      "Epoch 19: saving model to weights.ckpt\n",
      "3033/3387 [=========================>....] - ETA: 40s - loss: 4.6156 - accuracy: 0.2117\n",
      "Epoch 19: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 384s 113ms/step - loss: 4.6183 - accuracy: 0.2117\n",
      "Epoch 20/25\n",
      " 286/3387 [=>............................] - ETA: 5:49 - loss: 4.5897 - accuracy: 0.2143\n",
      "Epoch 20: saving model to weights.ckpt\n",
      " 926/3387 [=======>......................] - ETA: 4:31 - loss: 4.5953 - accuracy: 0.2140\n",
      "Epoch 20: saving model to weights.ckpt\n",
      "1566/3387 [============>.................] - ETA: 3:25 - loss: 4.5966 - accuracy: 0.2143\n",
      "Epoch 20: saving model to weights.ckpt\n",
      "2206/3387 [==================>...........] - ETA: 2:13 - loss: 4.6041 - accuracy: 0.2132\n",
      "Epoch 20: saving model to weights.ckpt\n",
      "2846/3387 [========================>.....] - ETA: 1:02 - loss: 4.6114 - accuracy: 0.2132\n",
      "Epoch 20: saving model to weights.ckpt\n",
      "3387/3387 [==============================] - 391s 115ms/step - loss: 4.6137 - accuracy: 0.2124\n",
      "Epoch 21/25\n",
      "  99/3387 [..............................] - ETA: 6:31 - loss: 4.5412 - accuracy: 0.2164\n",
      "Epoch 21: saving model to weights.ckpt\n",
      " 739/3387 [=====>........................] - ETA: 4:58 - loss: 4.5795 - accuracy: 0.2135\n",
      "Epoch 21: saving model to weights.ckpt\n",
      "1379/3387 [===========>..................] - ETA: 3:43 - loss: 4.5965 - accuracy: 0.2139\n",
      "Epoch 21: saving model to weights.ckpt\n",
      "1966/3387 [================>.............] - ETA: 2:39 - loss: 4.6024 - accuracy: 0.2141"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m cp_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m      5\u001b[0m     filepath\u001b[38;5;241m=\u001b[39mcheckpoint_path, \n\u001b[0;32m      6\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m      7\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m     save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39mbatch_size)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Train the model with the new callback\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=10*batch_size)\n",
    "\n",
    "# Train the model with the new callback\n",
    "model.fit(X_data, y_data, batch_size=batch_size, epochs=100,\n",
    "          callbacks=[cp_callback],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZelZIDjJKeJ"
   },
   "source": [
    "#### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "6O2O61hq35Xm"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import pickle as pk\n",
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9DymO4ad3Zh2"
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "\n",
    "pk.dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dcr1gslbJTwf"
   },
   "source": [
    "#### Loading Data into Memeory and Creating Text Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "OBR08KKN7X7e"
   },
   "outputs": [],
   "source": [
    "def buffering_document(filename):\n",
    "\t\n",
    "\tfile = open(filename, 'r')\n",
    "\tcontent = file.read()\n",
    "\tfile.close()\n",
    "\treturn content\n",
    " \n",
    "in_filename = 'plato_text_output.txt'\n",
    "document = buffering_document(in_filename)\n",
    "lines = document.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "OEmWWy-08B0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "-OaVE8Ex86pw"
   },
   "outputs": [],
   "source": [
    "tokenizer = load(open('tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86dxJz4hJkr3"
   },
   "source": [
    "#### Text Generation using RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ZpGuQcaX87Lm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ages the idea of marriage and of the family has been more and more defined and consecrated the civilized east is immeasurably in advance of any savage tribes the greeks and romans have improved upon the east the christian nations have been stricter in their views of the marriage relation than\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_content = lines[randint(0,len(lines))]\n",
    "print(seed_content + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "G16uGLFX8_1c"
   },
   "outputs": [],
   "source": [
    "cyphered = tokenizer.texts_to_sequences([seed_content])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "o8S4cq6f9Bdt"
   },
   "outputs": [],
   "source": [
    "#y_pred_data = model.predict_classes(cyphered, verbose=0)\n",
    "#y_pred_data = np.argmax(model.predict(cyphered), axis=-1)\n",
    "#y_pred_data = (model.predict(cyphered) > 0.5).astype(\"int32\") \n",
    "y_pred_data = np.argmax(cyphered, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7sjZ6ve39E64"
   },
   "outputs": [],
   "source": [
    "output_text = ''\n",
    "for word, index in tokenizer.word_index.items():\n",
    "\tif index == y_pred_data:\n",
    "\t\toutput_text = word\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Wabtg-uy9Ok4"
   },
   "outputs": [],
   "source": [
    "encoded = pad_sequences([cyphered], maxlen=chronology_len, truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "iP0hFDTe9Xzu"
   },
   "outputs": [],
   "source": [
    "def create_sequence(model, tokenizer, chronology_len, seed_content, n_words):\n",
    "\toutcome = list()\n",
    "\tinput_data = seed_content\n",
    "\n",
    "\tfor _ in range(n_words):\n",
    "\n",
    "\t\tcyphered = tokenizer.texts_to_sequences([input_data])[0]\n",
    "\n",
    "\t\tcyphered = pad_sequences([cyphered], maxlen=chronology_len, truncating='pre')\n",
    "\n",
    "\t\ty_pred_data = np.argmax(cyphered, axis=-1)\n",
    "\n",
    "\t\toutput_text = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == y_pred_data:\n",
    "\t\t\t\toutput_text = word\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tinput_data += ' ' + output_text\n",
    "\t\toutcome.append(output_text)\n",
    "\treturn ' '.join(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "6G4TrgZeChwM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they are or not which be that he a in is to and of the                                   \n"
     ]
    }
   ],
   "source": [
    "created = create_sequence(model, tokenizer, chronology_len, seed_content, 50)\n",
    "print(created)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Story Generation - Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
